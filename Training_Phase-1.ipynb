{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a60c471",
   "metadata": {},
   "source": [
    "# Training Phase-1 (Simple CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c5dfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\gnand\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\gnand\\anaconda3\\lib\\site-packages (from efficientnet_pytorch) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gnand\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from distutils.dir_util import copy_tree\n",
    "copy_tree(\"D:/Capstone Project/results/lib\", \"D:/Capstone Project/Working/\")\n",
    "!pip install efficientnet_pytorch\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append(\"D:/Capstone Project/results/lib\")\n",
    "\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db9e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import load_classifier_transforms, cycle, save_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c8eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CLASSIFIER_MODEL_GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df54e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import CLASSES\n",
    "from datasets import OrthonetClassificationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4a6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only 1 model architecture\n",
    "STOP_AFTER_EFFICIENTNET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058f07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "CSV_TRAIN_VAL = \"D:/Capstone Project/archive/train.csv\"\n",
    "DATA_PATH = \"D:/Capstone Project/archive/orthonet data/orthonet data new\"\n",
    "MODEL_DIR = \"D:/Capstone Project/Working\"\n",
    "\n",
    "WEIGHT_LOSS = True\n",
    "BS_TRAIN = 32\n",
    "BS_VAL = 32\n",
    "N_WORKERS = 2\n",
    "N_EPOCHS = 300\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ec4754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 train samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "Found 251 val samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "TRAIN\n",
      "396 unique patients\n",
      "Class                                             Number of samples\n",
      "Hip_SmithAndNephew_Polarstem_NilCol               51\n",
      "Knee_SmithAndNephew_GenesisII                     117\n",
      "Hip_Stryker_Exeter                                192\n",
      "Knee_Depuy_Synthes_Sigma                          78\n",
      "Hip_DepuySynthes_Corail_Collar                    102\n",
      "Hip_DepuySynthes_Corail_NilCol                    128\n",
      "Hip_JRIOrtho_FurlongEvolution_Collar              22\n",
      "Knee_SmithAndNephew_Legion2                       29\n",
      "Hip_Stryker_AccoladeII                            34\n",
      "Hip_SmithAndNephew_Anthology                      88\n",
      "Hip_JRIOrtho_FurlongEvolution_NilCol              22\n",
      "Knee_ZimmerBiomet_Oxford                          55\n",
      "\n",
      "\n",
      "VAL\n",
      "98 unique patients\n",
      "Class                                             Number of samples\n",
      "Knee_SmithAndNephew_GenesisII                     40\n",
      "Hip_SmithAndNephew_Anthology                      14\n",
      "Knee_Depuy_Synthes_Sigma                          36\n",
      "Hip_Stryker_Exeter                                26\n",
      "Hip_DepuySynthes_Corail_NilCol                    19\n",
      "Hip_SmithAndNephew_Polarstem_NilCol               21\n",
      "Hip_Stryker_AccoladeII                            14\n",
      "Hip_JRIOrtho_FurlongEvolution_Collar              27\n",
      "Hip_DepuySynthes_Corail_Collar                    37\n",
      "Hip_JRIOrtho_FurlongEvolution_NilCol              5\n",
      "Knee_ZimmerBiomet_Oxford                          12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_train = OrthonetClassificationDataset('train', CSV_TRAIN_VAL, DATA_PATH, None)\n",
    "ds_val = OrthonetClassificationDataset('val', CSV_TRAIN_VAL, DATA_PATH, None)\n",
    "\n",
    "print(f\"TRAIN\")\n",
    "ds_train.stats()\n",
    "print(f\"VAL\")\n",
    "ds_val.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6ef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 918 train samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "Found 251 val samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "Training efficientnet\n",
      "Epoch 001\t\tTRAIN loss: 2.5081\tTRAIN acc: 0.1270\tVAL loss: 2.4885*\tVAL acc: 0.0569\n",
      "Epoch 002\t\tTRAIN loss: 2.4736\tTRAIN acc: 0.1502\tVAL loss: 2.4876*\tVAL acc: 0.0749\n",
      "Epoch 003\t\tTRAIN loss: 2.4549\tTRAIN acc: 0.1598\tVAL loss: 2.4884\tVAL acc: 0.0757\n"
     ]
    }
   ],
   "source": [
    "results_by_model_by_epoch = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for model_type, model_generator in CLASSIFIER_MODEL_GENERATORS.items():\n",
    "\n",
    "    # Data\n",
    "    train_transforms, test_transforms = load_classifier_transforms()\n",
    "    ds_train = OrthonetClassificationDataset('train', CSV_TRAIN_VAL, DATA_PATH, train_transforms)\n",
    "    ds_val = OrthonetClassificationDataset('val', CSV_TRAIN_VAL, DATA_PATH, test_transforms)\n",
    "    dl_train = DataLoader(ds_train, BS_TRAIN, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n",
    "    dl_val = DataLoader(ds_val, BS_VAL, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n",
    "\n",
    "    # Model\n",
    "    model = model_generator(n_in=1, n_out=len(CLASSES)).to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW((p for p in model.parameters() if p.requires_grad), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=LEARNING_RATE*10, steps_per_epoch=len(dl_train), epochs=N_EPOCHS)\n",
    "    train_criterion = nn.CrossEntropyLoss(weight=ds_train.get_class_weights().to(DEVICE) if WEIGHT_LOSS else None)\n",
    "    test_criterion = nn.CrossEntropyLoss(weight=ds_train.get_class_weights().to(DEVICE) if WEIGHT_LOSS else None)\n",
    "\n",
    "    # Train\n",
    "    best_loss, best_path, last_save_path = 1e10, None, None\n",
    "\n",
    "    print(f\"Training {model_type}\")\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        train_loss, train_acc = cycle('train', model, dl_train, DEVICE, epoch, train_criterion, optimizer, scheduler)\n",
    "        val_loss, val_acc = cycle('test', model, dl_val, DEVICE, epoch, test_criterion, optimizer)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}\\t\\tTRAIN loss: {train_loss:.4f}\\tTRAIN acc: {train_acc:.4f}\\tVAL loss: {val_loss:.4f}{'*' if val_loss < best_loss else ''}\\tVAL acc: {val_acc:.4f}\")\n",
    "\n",
    "        state = {'epoch': epoch + 1,\n",
    "                 'state_dict': model.state_dict(),\n",
    "                 'optimizer': optimizer.state_dict(),\n",
    "                 'scheduler': scheduler}\n",
    "        save_path = os.path.join(MODEL_DIR, f\"{model_type}_{epoch}_{val_loss:.07f}.pt\")\n",
    "        best_loss, last_save_path = save_state(state, save_path, val_loss, best_loss, last_save_path)\n",
    "\n",
    "        results_by_model_by_epoch[model_type]['train_loss'].append(train_loss)\n",
    "        results_by_model_by_epoch[model_type]['train_acc'].append(train_acc)\n",
    "        results_by_model_by_epoch[model_type]['val_loss'].append(val_loss)\n",
    "        results_by_model_by_epoch[model_type]['val_acc'].append(val_acc)\n",
    "\n",
    "    with open(os.path.join(MODEL_DIR, f\"{model_type}_{best_loss}.txt\"), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(results_by_model_by_epoch[model_type].keys())\n",
    "        writer.writerows(zip(*results_by_model_by_epoch[model_type].values()))\n",
    "        \n",
    "    if STOP_AFTER_EFFICIENTNET:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67729f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
