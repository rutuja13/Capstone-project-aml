{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f400e9e",
   "metadata": {},
   "source": [
    "# Training Phase-2 (U-Net Segmentation Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23f1b3",
   "metadata": {},
   "source": [
    "## This network is trained to segment out the prosthesis present in radiograph which will be further used by the segmentation classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "744272cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\gnand\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\gnand\\anaconda3\\lib\\site-packages (from efficientnet_pytorch) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\gnand\\anaconda3\\lib\\site-packages (from torch->efficientnet_pytorch) (3.10.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from distutils.dir_util import copy_tree\n",
    "copy_tree(\"D:/Capstone Project/results/lib\", \"D:/Capstone Project/Working/\")\n",
    "!pip install efficientnet_pytorch\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import sys\n",
    "sys.path.append(\"D:/Capstone Project/results/lib\")\n",
    "\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b0a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import load_segmentation_transforms, save_state, cycle_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa12bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import get_unet\n",
    "from datasets import OrthonetSegmentationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c384cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "CSV_TRAIN_VAL = \"D:/Capstone Project/archive/train.csv\"\n",
    "DATA_PATH = \"D:/Capstone Project/archive/orthonet data/orthonet data new\"\n",
    "MODEL_DIR = \"D:/Capstone Project/Working\"\n",
    "\n",
    "FOLD = 2\n",
    "BS_TRAIN = 16\n",
    "BS_VAL = 16\n",
    "N_WORKERS = 2\n",
    "N_EPOCHS = 230\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38a547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 145 train samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "Found 53 val samples from D:/Capstone Project/archive/train.csv\n",
      "\n",
      "TRAIN\n",
      "108 unique patients\n",
      "Class                                             Number of samples\n",
      "Hip_SmithAndNephew_Polarstem_NilCol               15\n",
      "Knee_Depuy_Synthes_Sigma                          13\n",
      "Knee_SmithAndNephew_GenesisII                     19\n",
      "Hip_DepuySynthes_Corail_NilCol                    32\n",
      "Hip_JRIOrtho_FurlongEvolution_Collar              5\n",
      "Hip_Stryker_Exeter                                23\n",
      "Hip_DepuySynthes_Corail_Collar                    17\n",
      "Hip_Stryker_AccoladeII                            11\n",
      "Hip_SmithAndNephew_Anthology                      5\n",
      "Hip_JRIOrtho_FurlongEvolution_NilCol              2\n",
      "Knee_ZimmerBiomet_Oxford                          3\n",
      "\n",
      "\n",
      "VAL\n",
      "33 unique patients\n",
      "Class                                             Number of samples\n",
      "Knee_SmithAndNephew_GenesisII                     5\n",
      "Hip_SmithAndNephew_Anthology                      3\n",
      "Knee_Depuy_Synthes_Sigma                          9\n",
      "Hip_DepuySynthes_Corail_NilCol                    4\n",
      "Hip_SmithAndNephew_Polarstem_NilCol               6\n",
      "Hip_JRIOrtho_FurlongEvolution_Collar              10\n",
      "Hip_DepuySynthes_Corail_Collar                    10\n",
      "Hip_Stryker_AccoladeII                            4\n",
      "Hip_Stryker_Exeter                                2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "train_transforms, test_transforms = load_segmentation_transforms()\n",
    "ds_train = OrthonetSegmentationDataset('train', CSV_TRAIN_VAL, DATA_PATH, train_transforms)\n",
    "ds_val = OrthonetSegmentationDataset('val', CSV_TRAIN_VAL, DATA_PATH, test_transforms)\n",
    "dl_train = DataLoader(ds_train, BS_TRAIN, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n",
    "dl_val = DataLoader(ds_val, BS_VAL, shuffle=True, num_workers=N_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"TRAIN\")\n",
    "ds_train.stats()\n",
    "print(f\"VAL\")\n",
    "ds_val.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b09ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training U-NET\n",
      "Epoch 001\t\t\tTRAIN loss: 0.5549\tTRAIN Dice: 0.4133\tVAL loss: 0.7165\tVAL dice: 0.0983*\tJaccard Index: 0.0517\n",
      "Epoch 002\t\t\tTRAIN loss: 0.4690\tTRAIN Dice: 0.6250\tVAL loss: 0.6795\tVAL dice: 0.2315*\tJaccard Index: 0.1309\n",
      "Epoch 003\t\t\tTRAIN loss: 0.4317\tTRAIN Dice: 0.7029\tVAL loss: 0.5088\tVAL dice: 0.2419*\tJaccard Index: 0.1376\n",
      "Epoch 004\t\t\tTRAIN loss: 0.3872\tTRAIN Dice: 0.7341\tVAL loss: 0.4316\tVAL dice: 0.1416\tJaccard Index: 0.0762\n",
      "Epoch 005\t\t\tTRAIN loss: 0.3805\tTRAIN Dice: 0.7482\tVAL loss: 0.3819\tVAL dice: 0.4185*\tJaccard Index: 0.2646\n",
      "Epoch 006\t\t\tTRAIN loss: 0.3462\tTRAIN Dice: 0.7933\tVAL loss: 0.3339\tVAL dice: 0.7234*\tJaccard Index: 0.5666\n",
      "Epoch 007\t\t\tTRAIN loss: 0.3447\tTRAIN Dice: 0.7282\tVAL loss: 0.3417\tVAL dice: 0.8048*\tJaccard Index: 0.6734\n",
      "Epoch 008\t\t\tTRAIN loss: 0.3215\tTRAIN Dice: 0.7715\tVAL loss: 0.3120\tVAL dice: 0.6987\tJaccard Index: 0.5369\n",
      "Epoch 009\t\t\tTRAIN loss: 0.3308\tTRAIN Dice: 0.7582\tVAL loss: 0.3185\tVAL dice: 0.6031\tJaccard Index: 0.4317\n",
      "Epoch 010\t\t\tTRAIN loss: 0.3067\tTRAIN Dice: 0.7659\tVAL loss: 0.3255\tVAL dice: 0.7112\tJaccard Index: 0.5518\n",
      "Epoch 011\t\t\tTRAIN loss: 0.2975\tTRAIN Dice: 0.7870\tVAL loss: 0.2868\tVAL dice: 0.7727\tJaccard Index: 0.6296\n",
      "Epoch 012\t\t\tTRAIN loss: 0.3018\tTRAIN Dice: 0.7535\tVAL loss: 0.2842\tVAL dice: 0.7880\tJaccard Index: 0.6501\n",
      "Epoch 013\t\t\tTRAIN loss: 0.2847\tTRAIN Dice: 0.7772\tVAL loss: 0.3051\tVAL dice: 0.8039\tJaccard Index: 0.6721\n",
      "Epoch 014\t\t\tTRAIN loss: 0.2776\tTRAIN Dice: 0.7924\tVAL loss: 0.2807\tVAL dice: 0.8054*\tJaccard Index: 0.6742\n",
      "Epoch 015\t\t\tTRAIN loss: 0.2611\tTRAIN Dice: 0.7988\tVAL loss: 0.2555\tVAL dice: 0.8069*\tJaccard Index: 0.6763\n",
      "Epoch 016\t\t\tTRAIN loss: 0.2600\tTRAIN Dice: 0.8059\tVAL loss: 0.2583\tVAL dice: 0.6935\tJaccard Index: 0.5308\n",
      "Epoch 017\t\t\tTRAIN loss: 0.2505\tTRAIN Dice: 0.8018\tVAL loss: 0.2414\tVAL dice: 0.8202*\tJaccard Index: 0.6952\n",
      "Epoch 018\t\t\tTRAIN loss: 0.2788\tTRAIN Dice: 0.8089\tVAL loss: 0.2472\tVAL dice: 0.7519\tJaccard Index: 0.6024\n",
      "Epoch 019\t\t\tTRAIN loss: 0.2475\tTRAIN Dice: 0.7916\tVAL loss: 0.2744\tVAL dice: 0.7840\tJaccard Index: 0.6448\n",
      "Epoch 020\t\t\tTRAIN loss: 0.2578\tTRAIN Dice: 0.7017\tVAL loss: 0.3749\tVAL dice: 0.6654\tJaccard Index: 0.4986\n",
      "Epoch 021\t\t\tTRAIN loss: 0.2278\tTRAIN Dice: 0.7861\tVAL loss: 0.2212\tVAL dice: 0.7258\tJaccard Index: 0.5697\n",
      "Epoch 022\t\t\tTRAIN loss: 0.2183\tTRAIN Dice: 0.7912\tVAL loss: 0.2313\tVAL dice: 0.6736\tJaccard Index: 0.5079\n",
      "Epoch 023\t\t\tTRAIN loss: 0.2095\tTRAIN Dice: 0.8014\tVAL loss: 0.2192\tVAL dice: 0.6836\tJaccard Index: 0.5193\n",
      "Epoch 024\t\t\tTRAIN loss: 0.1960\tTRAIN Dice: 0.8281\tVAL loss: 0.1850\tVAL dice: 0.8529*\tJaccard Index: 0.7435\n",
      "Epoch 025\t\t\tTRAIN loss: 0.1871\tTRAIN Dice: 0.8266\tVAL loss: 0.1816\tVAL dice: 0.8615*\tJaccard Index: 0.7567\n",
      "Epoch 026\t\t\tTRAIN loss: 0.1818\tTRAIN Dice: 0.8260\tVAL loss: 0.1963\tVAL dice: 0.8644*\tJaccard Index: 0.7611\n",
      "Epoch 027\t\t\tTRAIN loss: 0.1725\tTRAIN Dice: 0.8208\tVAL loss: 0.1683\tVAL dice: 0.8199\tJaccard Index: 0.6947\n",
      "Epoch 028\t\t\tTRAIN loss: 0.1876\tTRAIN Dice: 0.8431\tVAL loss: 0.1676\tVAL dice: 0.8249\tJaccard Index: 0.7020\n",
      "Epoch 029\t\t\tTRAIN loss: 0.1629\tTRAIN Dice: 0.8155\tVAL loss: 0.1475\tVAL dice: 0.8525\tJaccard Index: 0.7429\n",
      "Epoch 030\t\t\tTRAIN loss: 0.1524\tTRAIN Dice: 0.8314\tVAL loss: 0.1590\tVAL dice: 0.7500\tJaccard Index: 0.6000\n",
      "Epoch 031\t\t\tTRAIN loss: 0.1490\tTRAIN Dice: 0.8163\tVAL loss: 0.1229\tVAL dice: 0.8736*\tJaccard Index: 0.7756\n",
      "Epoch 032\t\t\tTRAIN loss: 0.1356\tTRAIN Dice: 0.8489\tVAL loss: 0.1325\tVAL dice: 0.8492\tJaccard Index: 0.7379\n",
      "Epoch 033\t\t\tTRAIN loss: 0.1369\tTRAIN Dice: 0.8450\tVAL loss: 0.2161\tVAL dice: 0.7514\tJaccard Index: 0.6019\n",
      "Epoch 034\t\t\tTRAIN loss: 0.1541\tTRAIN Dice: 0.7392\tVAL loss: 0.1599\tVAL dice: 0.6960\tJaccard Index: 0.5338\n",
      "Epoch 035\t\t\tTRAIN loss: 0.1431\tTRAIN Dice: 0.7466\tVAL loss: 0.1278\tVAL dice: 0.7413\tJaccard Index: 0.5890\n",
      "Epoch 036\t\t\tTRAIN loss: 0.1217\tTRAIN Dice: 0.8243\tVAL loss: 0.1216\tVAL dice: 0.8298\tJaccard Index: 0.7091\n",
      "Epoch 037\t\t\tTRAIN loss: 0.1219\tTRAIN Dice: 0.8051\tVAL loss: 0.1055\tVAL dice: 0.8416\tJaccard Index: 0.7266\n",
      "Epoch 038\t\t\tTRAIN loss: 0.1136\tTRAIN Dice: 0.8262\tVAL loss: 0.1934\tVAL dice: 0.2911\tJaccard Index: 0.1704\n",
      "Epoch 039\t\t\tTRAIN loss: 0.1073\tTRAIN Dice: 0.8332\tVAL loss: 0.1000\tVAL dice: 0.8143\tJaccard Index: 0.6867\n",
      "Epoch 040\t\t\tTRAIN loss: 0.1009\tTRAIN Dice: 0.8372\tVAL loss: 0.1372\tVAL dice: 0.6896\tJaccard Index: 0.5262\n",
      "Epoch 041\t\t\tTRAIN loss: 0.0969\tTRAIN Dice: 0.8466\tVAL loss: 0.0801\tVAL dice: 0.8621\tJaccard Index: 0.7576\n",
      "Epoch 042\t\t\tTRAIN loss: 0.0904\tTRAIN Dice: 0.8584\tVAL loss: 0.0835\tVAL dice: 0.8520\tJaccard Index: 0.7422\n",
      "Epoch 043\t\t\tTRAIN loss: 0.0983\tTRAIN Dice: 0.8256\tVAL loss: 0.0897\tVAL dice: 0.8373\tJaccard Index: 0.7201\n",
      "Epoch 044\t\t\tTRAIN loss: 0.0859\tTRAIN Dice: 0.8472\tVAL loss: 0.0758\tVAL dice: 0.8652\tJaccard Index: 0.7625\n",
      "Epoch 045\t\t\tTRAIN loss: 0.0865\tTRAIN Dice: 0.8424\tVAL loss: 0.1609\tVAL dice: 0.4661\tJaccard Index: 0.3038\n",
      "Epoch 046\t\t\tTRAIN loss: 0.0955\tTRAIN Dice: 0.8616\tVAL loss: 0.1183\tVAL dice: 0.7281\tJaccard Index: 0.5724\n",
      "Epoch 047\t\t\tTRAIN loss: 0.0872\tTRAIN Dice: 0.8436\tVAL loss: 0.0695\tVAL dice: 0.8709\tJaccard Index: 0.7713\n",
      "Epoch 048\t\t\tTRAIN loss: 0.0782\tTRAIN Dice: 0.8653\tVAL loss: 0.0750\tVAL dice: 0.8639\tJaccard Index: 0.7605\n",
      "Epoch 049\t\t\tTRAIN loss: 0.0769\tTRAIN Dice: 0.8552\tVAL loss: 0.1276\tVAL dice: 0.6824\tJaccard Index: 0.5179\n",
      "Epoch 050\t\t\tTRAIN loss: 0.0719\tTRAIN Dice: 0.8621\tVAL loss: 0.1409\tVAL dice: 0.7760\tJaccard Index: 0.6339\n",
      "Epoch 051\t\t\tTRAIN loss: 0.0934\tTRAIN Dice: 0.8440\tVAL loss: 0.1469\tVAL dice: 0.4604\tJaccard Index: 0.2990\n",
      "Epoch 052\t\t\tTRAIN loss: 0.0746\tTRAIN Dice: 0.8683\tVAL loss: 0.0888\tVAL dice: 0.8584\tJaccard Index: 0.7520\n",
      "Epoch 053\t\t\tTRAIN loss: 0.0689\tTRAIN Dice: 0.8685\tVAL loss: 0.0607\tVAL dice: 0.8776*\tJaccard Index: 0.7820\n",
      "Epoch 054\t\t\tTRAIN loss: 0.0926\tTRAIN Dice: 0.8616\tVAL loss: 0.0627\tVAL dice: 0.8791*\tJaccard Index: 0.7842\n",
      "Epoch 055\t\t\tTRAIN loss: 0.1117\tTRAIN Dice: 0.8614\tVAL loss: 0.1098\tVAL dice: 0.7012\tJaccard Index: 0.5399\n",
      "Epoch 056\t\t\tTRAIN loss: 0.0950\tTRAIN Dice: 0.8372\tVAL loss: 0.1455\tVAL dice: 0.7448\tJaccard Index: 0.5934\n",
      "Epoch 057\t\t\tTRAIN loss: 0.0759\tTRAIN Dice: 0.8280\tVAL loss: 0.1249\tVAL dice: 0.6039\tJaccard Index: 0.4326\n",
      "Epoch 058\t\t\tTRAIN loss: 0.1151\tTRAIN Dice: 0.8397\tVAL loss: 0.0621\tVAL dice: 0.8771\tJaccard Index: 0.7812\n",
      "Epoch 059\t\t\tTRAIN loss: 0.0740\tTRAIN Dice: 0.8527\tVAL loss: 0.0709\tVAL dice: 0.8612\tJaccard Index: 0.7562\n",
      "Epoch 060\t\t\tTRAIN loss: 0.0735\tTRAIN Dice: 0.8306\tVAL loss: 0.0656\tVAL dice: 0.8687\tJaccard Index: 0.7679\n",
      "Epoch 061\t\t\tTRAIN loss: 0.0660\tTRAIN Dice: 0.8663\tVAL loss: 0.0575\tVAL dice: 0.8719\tJaccard Index: 0.7729\n",
      "Epoch 062\t\t\tTRAIN loss: 0.0624\tTRAIN Dice: 0.8751\tVAL loss: 0.0480\tVAL dice: 0.8820*\tJaccard Index: 0.7889\n",
      "Epoch 063\t\t\tTRAIN loss: 0.0618\tTRAIN Dice: 0.8725\tVAL loss: 0.0609\tVAL dice: 0.8933*\tJaccard Index: 0.8072\n",
      "Epoch 064\t\t\tTRAIN loss: 0.0606\tTRAIN Dice: 0.8667\tVAL loss: 0.0651\tVAL dice: 0.8682\tJaccard Index: 0.7671\n",
      "Epoch 065\t\t\tTRAIN loss: 0.0638\tTRAIN Dice: 0.8616\tVAL loss: 0.1852\tVAL dice: 0.2203\tJaccard Index: 0.1238\n",
      "Epoch 066\t\t\tTRAIN loss: 0.0952\tTRAIN Dice: 0.8449\tVAL loss: 0.2126\tVAL dice: 0.0066\tJaccard Index: 0.0033\n",
      "Epoch 067\t\t\tTRAIN loss: 0.0935\tTRAIN Dice: 0.7642\tVAL loss: 0.0770\tVAL dice: 0.7980\tJaccard Index: 0.6639\n",
      "Epoch 068\t\t\tTRAIN loss: 0.0880\tTRAIN Dice: 0.8349\tVAL loss: 0.0841\tVAL dice: 0.7022\tJaccard Index: 0.5411\n",
      "Epoch 069\t\t\tTRAIN loss: 0.1268\tTRAIN Dice: 0.6288\tVAL loss: 0.0709\tVAL dice: 0.7851\tJaccard Index: 0.6462\n",
      "Epoch 070\t\t\tTRAIN loss: 0.1032\tTRAIN Dice: 0.7918\tVAL loss: 0.1495\tVAL dice: 0.4561\tJaccard Index: 0.2955\n",
      "Epoch 071\t\t\tTRAIN loss: 0.0885\tTRAIN Dice: 0.7727\tVAL loss: 0.0801\tVAL dice: 0.8261\tJaccard Index: 0.7037\n",
      "Epoch 072\t\t\tTRAIN loss: 0.0794\tTRAIN Dice: 0.8121\tVAL loss: 0.0683\tVAL dice: 0.8487\tJaccard Index: 0.7372\n",
      "Epoch 073\t\t\tTRAIN loss: 0.0653\tTRAIN Dice: 0.8531\tVAL loss: 0.0555\tVAL dice: 0.8745\tJaccard Index: 0.7770\n",
      "Epoch 074\t\t\tTRAIN loss: 0.0652\tTRAIN Dice: 0.8533\tVAL loss: 0.0728\tVAL dice: 0.8211\tJaccard Index: 0.6964\n",
      "Epoch 075\t\t\tTRAIN loss: 0.0705\tTRAIN Dice: 0.8503\tVAL loss: 0.0537\tVAL dice: 0.8811\tJaccard Index: 0.7875\n",
      "Epoch 076\t\t\tTRAIN loss: 0.0736\tTRAIN Dice: 0.8488\tVAL loss: 0.0534\tVAL dice: 0.8607\tJaccard Index: 0.7555\n",
      "Epoch 077\t\t\tTRAIN loss: 0.0639\tTRAIN Dice: 0.8566\tVAL loss: 0.0535\tVAL dice: 0.8674\tJaccard Index: 0.7658\n",
      "Epoch 078\t\t\tTRAIN loss: 0.0771\tTRAIN Dice: 0.8511\tVAL loss: 0.0694\tVAL dice: 0.8491\tJaccard Index: 0.7377\n",
      "Epoch 079\t\t\tTRAIN loss: 0.0581\tTRAIN Dice: 0.8711\tVAL loss: 0.0450\tVAL dice: 0.8835\tJaccard Index: 0.7913\n",
      "Epoch 080\t\t\tTRAIN loss: 0.0630\tTRAIN Dice: 0.8676\tVAL loss: 0.0616\tVAL dice: 0.8686\tJaccard Index: 0.7677\n",
      "Epoch 081\t\t\tTRAIN loss: 0.0785\tTRAIN Dice: 0.8421\tVAL loss: 0.3802\tVAL dice: 0.0033\tJaccard Index: 0.0017\n",
      "Epoch 082\t\t\tTRAIN loss: 0.1117\tTRAIN Dice: 0.7004\tVAL loss: 0.2343\tVAL dice: 0.6942\tJaccard Index: 0.5316\n",
      "Epoch 083\t\t\tTRAIN loss: 0.0802\tTRAIN Dice: 0.8030\tVAL loss: 0.0763\tVAL dice: 0.8062\tJaccard Index: 0.6753\n",
      "Epoch 084\t\t\tTRAIN loss: 0.0695\tTRAIN Dice: 0.8263\tVAL loss: 0.0615\tVAL dice: 0.8322\tJaccard Index: 0.7126\n",
      "Epoch 085\t\t\tTRAIN loss: 0.0674\tTRAIN Dice: 0.8475\tVAL loss: 0.0621\tVAL dice: 0.8436\tJaccard Index: 0.7295\n",
      "Epoch 086\t\t\tTRAIN loss: 0.0664\tTRAIN Dice: 0.8402\tVAL loss: 0.0512\tVAL dice: 0.8613\tJaccard Index: 0.7563\n",
      "Epoch 087\t\t\tTRAIN loss: 0.0771\tTRAIN Dice: 0.8447\tVAL loss: 0.0644\tVAL dice: 0.8647\tJaccard Index: 0.7617\n",
      "Epoch 088\t\t\tTRAIN loss: 0.0586\tTRAIN Dice: 0.8613\tVAL loss: 0.0738\tVAL dice: 0.8112\tJaccard Index: 0.6823\n",
      "Epoch 089\t\t\tTRAIN loss: 0.0848\tTRAIN Dice: 0.8644\tVAL loss: 0.0685\tVAL dice: 0.8731\tJaccard Index: 0.7748\n",
      "Epoch 090\t\t\tTRAIN loss: 0.0616\tTRAIN Dice: 0.8524\tVAL loss: 0.0459\tVAL dice: 0.8784\tJaccard Index: 0.7832\n",
      "Epoch 091\t\t\tTRAIN loss: 0.0868\tTRAIN Dice: 0.8734\tVAL loss: 0.0546\tVAL dice: 0.8757\tJaccard Index: 0.7788\n",
      "Epoch 092\t\t\tTRAIN loss: 0.0575\tTRAIN Dice: 0.8745\tVAL loss: 0.0588\tVAL dice: 0.8524\tJaccard Index: 0.7428\n",
      "Epoch 093\t\t\tTRAIN loss: 0.0599\tTRAIN Dice: 0.8615\tVAL loss: 0.0512\tVAL dice: 0.8822\tJaccard Index: 0.7892\n",
      "Epoch 094\t\t\tTRAIN loss: 0.0614\tTRAIN Dice: 0.8631\tVAL loss: 0.0649\tVAL dice: 0.8474\tJaccard Index: 0.7352\n",
      "Epoch 095\t\t\tTRAIN loss: 0.0586\tTRAIN Dice: 0.8700\tVAL loss: 0.0590\tVAL dice: 0.8698\tJaccard Index: 0.7696\n",
      "Epoch 096\t\t\tTRAIN loss: 0.0585\tTRAIN Dice: 0.8605\tVAL loss: 0.0546\tVAL dice: 0.8658\tJaccard Index: 0.7633\n",
      "Epoch 097\t\t\tTRAIN loss: 0.0566\tTRAIN Dice: 0.8640\tVAL loss: 0.0521\tVAL dice: 0.8769\tJaccard Index: 0.7808\n",
      "Epoch 098\t\t\tTRAIN loss: 0.0522\tTRAIN Dice: 0.8878\tVAL loss: 0.0441\tVAL dice: 0.8866\tJaccard Index: 0.7963\n",
      "Epoch 099\t\t\tTRAIN loss: 0.0554\tTRAIN Dice: 0.8774\tVAL loss: 0.0446\tVAL dice: 0.8831\tJaccard Index: 0.7907\n",
      "Epoch 100\t\t\tTRAIN loss: 0.0568\tTRAIN Dice: 0.8629\tVAL loss: 0.0705\tVAL dice: 0.8459\tJaccard Index: 0.7330\n",
      "Epoch 101\t\t\tTRAIN loss: 0.0671\tTRAIN Dice: 0.8530\tVAL loss: 0.0486\tVAL dice: 0.8696\tJaccard Index: 0.7693\n",
      "Epoch 102\t\t\tTRAIN loss: 0.0617\tTRAIN Dice: 0.8547\tVAL loss: 0.0516\tVAL dice: 0.8662\tJaccard Index: 0.7640\n",
      "Epoch 103\t\t\tTRAIN loss: 0.0646\tTRAIN Dice: 0.8396\tVAL loss: 0.0533\tVAL dice: 0.8523\tJaccard Index: 0.7425\n",
      "Epoch 104\t\t\tTRAIN loss: 0.0779\tTRAIN Dice: 0.8677\tVAL loss: 0.0605\tVAL dice: 0.8598\tJaccard Index: 0.7541\n",
      "Epoch 105\t\t\tTRAIN loss: 0.0518\tTRAIN Dice: 0.8813\tVAL loss: 0.0525\tVAL dice: 0.8786\tJaccard Index: 0.7834\n",
      "Epoch 106\t\t\tTRAIN loss: 0.0558\tTRAIN Dice: 0.8713\tVAL loss: 0.0456\tVAL dice: 0.8817\tJaccard Index: 0.7884\n",
      "Epoch 107\t\t\tTRAIN loss: 0.0527\tTRAIN Dice: 0.8821\tVAL loss: 0.0406\tVAL dice: 0.8878\tJaccard Index: 0.7982\n",
      "Epoch 108\t\t\tTRAIN loss: 0.0546\tTRAIN Dice: 0.8633\tVAL loss: 0.0562\tVAL dice: 0.8541\tJaccard Index: 0.7453\n",
      "Epoch 109\t\t\tTRAIN loss: 0.0518\tTRAIN Dice: 0.8692\tVAL loss: 0.0464\tVAL dice: 0.8882\tJaccard Index: 0.7988\n",
      "Epoch 110\t\t\tTRAIN loss: 0.0560\tTRAIN Dice: 0.8754\tVAL loss: 0.0394\tVAL dice: 0.8892\tJaccard Index: 0.8005\n",
      "Epoch 111\t\t\tTRAIN loss: 0.0623\tTRAIN Dice: 0.8765\tVAL loss: 0.0469\tVAL dice: 0.8909\tJaccard Index: 0.8032\n",
      "Epoch 112\t\t\tTRAIN loss: 0.0642\tTRAIN Dice: 0.8518\tVAL loss: 0.0519\tVAL dice: 0.8670\tJaccard Index: 0.7652\n",
      "Epoch 113\t\t\tTRAIN loss: 0.0643\tTRAIN Dice: 0.8497\tVAL loss: 0.0596\tVAL dice: 0.8243\tJaccard Index: 0.7011\n",
      "Epoch 114\t\t\tTRAIN loss: 0.0794\tTRAIN Dice: 0.8591\tVAL loss: 0.0503\tVAL dice: 0.8558\tJaccard Index: 0.7479\n",
      "Epoch 115\t\t\tTRAIN loss: 0.0606\tTRAIN Dice: 0.8558\tVAL loss: 0.0630\tVAL dice: 0.8650\tJaccard Index: 0.7622\n",
      "Epoch 116\t\t\tTRAIN loss: 0.0543\tTRAIN Dice: 0.8812\tVAL loss: 0.0415\tVAL dice: 0.8867\tJaccard Index: 0.7964\n",
      "Epoch 117\t\t\tTRAIN loss: 0.0536\tTRAIN Dice: 0.8704\tVAL loss: 0.0812\tVAL dice: 0.8049\tJaccard Index: 0.6735\n",
      "Epoch 118\t\t\tTRAIN loss: 0.0524\tTRAIN Dice: 0.8791\tVAL loss: 0.0455\tVAL dice: 0.8930\tJaccard Index: 0.8066\n",
      "Epoch 119\t\t\tTRAIN loss: 0.0555\tTRAIN Dice: 0.8797\tVAL loss: 0.0496\tVAL dice: 0.8905\tJaccard Index: 0.8025\n",
      "Epoch 120\t\t\tTRAIN loss: 0.0562\tTRAIN Dice: 0.8640\tVAL loss: 0.0696\tVAL dice: 0.8606\tJaccard Index: 0.7553\n",
      "Epoch 121\t\t\tTRAIN loss: 0.0493\tTRAIN Dice: 0.8876\tVAL loss: 0.0414\tVAL dice: 0.8831\tJaccard Index: 0.7907\n",
      "Epoch 122\t\t\tTRAIN loss: 0.0544\tTRAIN Dice: 0.8753\tVAL loss: 0.0538\tVAL dice: 0.8807\tJaccard Index: 0.7869\n",
      "Epoch 123\t\t\tTRAIN loss: 0.0503\tTRAIN Dice: 0.8769\tVAL loss: 0.0389\tVAL dice: 0.8833\tJaccard Index: 0.7910\n",
      "Epoch 124\t\t\tTRAIN loss: 0.0514\tTRAIN Dice: 0.8878\tVAL loss: 0.0420\tVAL dice: 0.8902\tJaccard Index: 0.8021\n",
      "Epoch 125\t\t\tTRAIN loss: 0.0457\tTRAIN Dice: 0.8854\tVAL loss: 0.0535\tVAL dice: 0.8748\tJaccard Index: 0.7775\n",
      "Epoch 126\t\t\tTRAIN loss: 0.0595\tTRAIN Dice: 0.8700\tVAL loss: 0.0425\tVAL dice: 0.8801\tJaccard Index: 0.7859\n",
      "Epoch 127\t\t\tTRAIN loss: 0.0499\tTRAIN Dice: 0.8843\tVAL loss: 0.0382\tVAL dice: 0.8907\tJaccard Index: 0.8029\n",
      "Epoch 128\t\t\tTRAIN loss: 0.0546\tTRAIN Dice: 0.8674\tVAL loss: 0.0467\tVAL dice: 0.8942*\tJaccard Index: 0.8086\n",
      "Epoch 129\t\t\tTRAIN loss: 0.0486\tTRAIN Dice: 0.8861\tVAL loss: 0.0373\tVAL dice: 0.8941\tJaccard Index: 0.8085\n",
      "Epoch 130\t\t\tTRAIN loss: 0.0468\tTRAIN Dice: 0.8914\tVAL loss: 0.0378\tVAL dice: 0.8924\tJaccard Index: 0.8057\n",
      "Epoch 131\t\t\tTRAIN loss: 0.0509\tTRAIN Dice: 0.8759\tVAL loss: 0.0391\tVAL dice: 0.8908\tJaccard Index: 0.8032\n",
      "Epoch 132\t\t\tTRAIN loss: 0.0541\tTRAIN Dice: 0.8776\tVAL loss: 0.0430\tVAL dice: 0.8881\tJaccard Index: 0.7988\n",
      "Epoch 133\t\t\tTRAIN loss: 0.0545\tTRAIN Dice: 0.8765\tVAL loss: 0.0391\tVAL dice: 0.8860\tJaccard Index: 0.7953\n",
      "Epoch 134\t\t\tTRAIN loss: 0.0493\tTRAIN Dice: 0.8871\tVAL loss: 0.0415\tVAL dice: 0.8853\tJaccard Index: 0.7942\n",
      "Epoch 135\t\t\tTRAIN loss: 0.0505\tTRAIN Dice: 0.8850\tVAL loss: 0.0400\tVAL dice: 0.8890\tJaccard Index: 0.8001\n",
      "Epoch 136\t\t\tTRAIN loss: 0.0498\tTRAIN Dice: 0.8780\tVAL loss: 0.0688\tVAL dice: 0.8181\tJaccard Index: 0.6922\n",
      "Epoch 137\t\t\tTRAIN loss: 0.0688\tTRAIN Dice: 0.8735\tVAL loss: 0.0532\tVAL dice: 0.8776\tJaccard Index: 0.7818\n",
      "Epoch 138\t\t\tTRAIN loss: 0.0526\tTRAIN Dice: 0.8744\tVAL loss: 0.0469\tVAL dice: 0.8714\tJaccard Index: 0.7721\n",
      "Epoch 139\t\t\tTRAIN loss: 0.0588\tTRAIN Dice: 0.8665\tVAL loss: 0.0382\tVAL dice: 0.8907\tJaccard Index: 0.8029\n",
      "Epoch 140\t\t\tTRAIN loss: 0.0753\tTRAIN Dice: 0.8720\tVAL loss: 0.0495\tVAL dice: 0.8865\tJaccard Index: 0.7962\n",
      "Epoch 141\t\t\tTRAIN loss: 0.0509\tTRAIN Dice: 0.8825\tVAL loss: 0.0591\tVAL dice: 0.8728\tJaccard Index: 0.7743\n",
      "Epoch 142\t\t\tTRAIN loss: 0.0511\tTRAIN Dice: 0.8828\tVAL loss: 0.0384\tVAL dice: 0.8932\tJaccard Index: 0.8070\n",
      "Epoch 143\t\t\tTRAIN loss: 0.0443\tTRAIN Dice: 0.8939\tVAL loss: 0.0391\tVAL dice: 0.8907\tJaccard Index: 0.8029\n",
      "Epoch 144\t\t\tTRAIN loss: 0.0522\tTRAIN Dice: 0.8771\tVAL loss: 0.0464\tVAL dice: 0.8951*\tJaccard Index: 0.8101\n",
      "Epoch 145\t\t\tTRAIN loss: 0.0495\tTRAIN Dice: 0.8805\tVAL loss: 0.0375\tVAL dice: 0.8911\tJaccard Index: 0.8036\n",
      "Epoch 146\t\t\tTRAIN loss: 0.0552\tTRAIN Dice: 0.8710\tVAL loss: 0.0473\tVAL dice: 0.8854\tJaccard Index: 0.7944\n",
      "Epoch 147\t\t\tTRAIN loss: 0.0474\tTRAIN Dice: 0.8848\tVAL loss: 0.0391\tVAL dice: 0.8915\tJaccard Index: 0.8042\n",
      "Epoch 148\t\t\tTRAIN loss: 0.0515\tTRAIN Dice: 0.8766\tVAL loss: 0.0375\tVAL dice: 0.8952*\tJaccard Index: 0.8102\n",
      "Epoch 149\t\t\tTRAIN loss: 0.0816\tTRAIN Dice: 0.8926\tVAL loss: 0.0477\tVAL dice: 0.8952*\tJaccard Index: 0.8102\n",
      "Epoch 150\t\t\tTRAIN loss: 0.0533\tTRAIN Dice: 0.8862\tVAL loss: 0.0412\tVAL dice: 0.8933\tJaccard Index: 0.8072\n",
      "Epoch 151\t\t\tTRAIN loss: 0.0464\tTRAIN Dice: 0.8867\tVAL loss: 0.0412\tVAL dice: 0.8954*\tJaccard Index: 0.8107\n",
      "Epoch 152\t\t\tTRAIN loss: 0.0485\tTRAIN Dice: 0.8814\tVAL loss: 0.0363\tVAL dice: 0.8922\tJaccard Index: 0.8054\n",
      "Epoch 153\t\t\tTRAIN loss: 0.0488\tTRAIN Dice: 0.8886\tVAL loss: 0.0421\tVAL dice: 0.8956*\tJaccard Index: 0.8109\n",
      "Epoch 154\t\t\tTRAIN loss: 0.0507\tTRAIN Dice: 0.8818\tVAL loss: 0.0400\tVAL dice: 0.8934\tJaccard Index: 0.8073\n",
      "Epoch 155\t\t\tTRAIN loss: 0.0488\tTRAIN Dice: 0.8900\tVAL loss: 0.0358\tVAL dice: 0.8967*\tJaccard Index: 0.8128\n",
      "Epoch 156\t\t\tTRAIN loss: 0.0495\tTRAIN Dice: 0.8852\tVAL loss: 0.0372\tVAL dice: 0.8969*\tJaccard Index: 0.8130\n",
      "Epoch 157\t\t\tTRAIN loss: 0.0504\tTRAIN Dice: 0.8745\tVAL loss: 0.0381\tVAL dice: 0.8921\tJaccard Index: 0.8052\n",
      "Epoch 158\t\t\tTRAIN loss: 0.0457\tTRAIN Dice: 0.8861\tVAL loss: 0.0492\tVAL dice: 0.8892\tJaccard Index: 0.8005\n",
      "Epoch 159\t\t\tTRAIN loss: 0.0460\tTRAIN Dice: 0.8909\tVAL loss: 0.0375\tVAL dice: 0.8936\tJaccard Index: 0.8077\n",
      "Epoch 160\t\t\tTRAIN loss: 0.0579\tTRAIN Dice: 0.8846\tVAL loss: 0.0819\tVAL dice: 0.7849\tJaccard Index: 0.6460\n",
      "Epoch 161\t\t\tTRAIN loss: 0.0614\tTRAIN Dice: 0.8567\tVAL loss: 0.0519\tVAL dice: 0.8554\tJaccard Index: 0.7473\n",
      "Epoch 162\t\t\tTRAIN loss: 0.0540\tTRAIN Dice: 0.8683\tVAL loss: 0.0452\tVAL dice: 0.8743\tJaccard Index: 0.7767\n",
      "Epoch 163\t\t\tTRAIN loss: 0.0567\tTRAIN Dice: 0.8653\tVAL loss: 0.0580\tVAL dice: 0.8640\tJaccard Index: 0.7606\n",
      "Epoch 164\t\t\tTRAIN loss: 0.1443\tTRAIN Dice: 0.8768\tVAL loss: 0.0444\tVAL dice: 0.8871\tJaccard Index: 0.7971\n",
      "Epoch 165\t\t\tTRAIN loss: 0.0544\tTRAIN Dice: 0.8762\tVAL loss: 0.0532\tVAL dice: 0.8730\tJaccard Index: 0.7747\n",
      "Epoch 166\t\t\tTRAIN loss: 0.0542\tTRAIN Dice: 0.8746\tVAL loss: 0.0481\tVAL dice: 0.8794\tJaccard Index: 0.7847\n",
      "Epoch 167\t\t\tTRAIN loss: 0.0623\tTRAIN Dice: 0.8730\tVAL loss: 0.0479\tVAL dice: 0.8844\tJaccard Index: 0.7928\n",
      "Epoch 168\t\t\tTRAIN loss: 0.0488\tTRAIN Dice: 0.8804\tVAL loss: 0.0438\tVAL dice: 0.8999*\tJaccard Index: 0.8180\n",
      "Epoch 169\t\t\tTRAIN loss: 0.0504\tTRAIN Dice: 0.8810\tVAL loss: 0.0365\tVAL dice: 0.8956\tJaccard Index: 0.8109\n",
      "Epoch 170\t\t\tTRAIN loss: 0.0502\tTRAIN Dice: 0.8877\tVAL loss: 0.0374\tVAL dice: 0.8965\tJaccard Index: 0.8124\n",
      "Epoch 171\t\t\tTRAIN loss: 0.0733\tTRAIN Dice: 0.8848\tVAL loss: 0.0351\tVAL dice: 0.8997\tJaccard Index: 0.8177\n",
      "Epoch 172\t\t\tTRAIN loss: 0.0483\tTRAIN Dice: 0.8851\tVAL loss: 0.0448\tVAL dice: 0.8958\tJaccard Index: 0.8113\n",
      "Epoch 173\t\t\tTRAIN loss: 0.0476\tTRAIN Dice: 0.8872\tVAL loss: 0.0375\tVAL dice: 0.8952\tJaccard Index: 0.8103\n",
      "Epoch 174\t\t\tTRAIN loss: 0.0632\tTRAIN Dice: 0.8818\tVAL loss: 0.0367\tVAL dice: 0.8921\tJaccard Index: 0.8053\n",
      "Epoch 175\t\t\tTRAIN loss: 0.0512\tTRAIN Dice: 0.8769\tVAL loss: 0.0492\tVAL dice: 0.8917\tJaccard Index: 0.8046\n",
      "Epoch 176\t\t\tTRAIN loss: 0.0499\tTRAIN Dice: 0.8831\tVAL loss: 0.0394\tVAL dice: 0.8924\tJaccard Index: 0.8057\n",
      "Epoch 177\t\t\tTRAIN loss: 0.0509\tTRAIN Dice: 0.8718\tVAL loss: 0.0429\tVAL dice: 0.8966\tJaccard Index: 0.8125\n",
      "Epoch 178\t\t\tTRAIN loss: 0.0459\tTRAIN Dice: 0.8842\tVAL loss: 0.0373\tVAL dice: 0.8977\tJaccard Index: 0.8143\n",
      "Epoch 179\t\t\tTRAIN loss: 0.0529\tTRAIN Dice: 0.8769\tVAL loss: 0.0412\tVAL dice: 0.8951\tJaccard Index: 0.8101\n",
      "Epoch 180\t\t\tTRAIN loss: 0.0468\tTRAIN Dice: 0.8904\tVAL loss: 0.0423\tVAL dice: 0.8925\tJaccard Index: 0.8059\n",
      "Epoch 181\t\t\tTRAIN loss: 0.0468\tTRAIN Dice: 0.8816\tVAL loss: 0.0399\tVAL dice: 0.8888\tJaccard Index: 0.7998\n",
      "Epoch 182\t\t\tTRAIN loss: 0.0640\tTRAIN Dice: 0.8866\tVAL loss: 0.0455\tVAL dice: 0.8913\tJaccard Index: 0.8039\n",
      "Epoch 183\t\t\tTRAIN loss: 0.0512\tTRAIN Dice: 0.8744\tVAL loss: 0.0371\tVAL dice: 0.8911\tJaccard Index: 0.8036\n",
      "Epoch 184\t\t\tTRAIN loss: 0.0467\tTRAIN Dice: 0.8870\tVAL loss: 0.0541\tVAL dice: 0.8896\tJaccard Index: 0.8012\n",
      "Epoch 185\t\t\tTRAIN loss: 0.0479\tTRAIN Dice: 0.8923\tVAL loss: 0.0375\tVAL dice: 0.8929\tJaccard Index: 0.8065\n",
      "Epoch 186\t\t\tTRAIN loss: 0.0508\tTRAIN Dice: 0.8810\tVAL loss: 0.0355\tVAL dice: 0.8960\tJaccard Index: 0.8116\n",
      "Epoch 187\t\t\tTRAIN loss: 0.0448\tTRAIN Dice: 0.8905\tVAL loss: 0.0355\tVAL dice: 0.8973\tJaccard Index: 0.8138\n",
      "Epoch 188\t\t\tTRAIN loss: 0.0695\tTRAIN Dice: 0.8796\tVAL loss: 0.0628\tVAL dice: 0.8945\tJaccard Index: 0.8092\n",
      "Epoch 189\t\t\tTRAIN loss: 0.0452\tTRAIN Dice: 0.8917\tVAL loss: 0.0514\tVAL dice: 0.8949\tJaccard Index: 0.8098\n",
      "Epoch 190\t\t\tTRAIN loss: 0.0478\tTRAIN Dice: 0.8860\tVAL loss: 0.0384\tVAL dice: 0.8968\tJaccard Index: 0.8128\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "model = get_unet(n_in=1, n_out=1).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW((p for p in model.parameters() if p.requires_grad), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=LEARNING_RATE*10, steps_per_epoch=len(dl_train), epochs=N_EPOCHS)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train\n",
    "best_dice, best_path, last_save_path = 0, None, None\n",
    "\n",
    "print(f\"Training U-NET\")\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss, train_acc, train_dice = cycle_seg('train', model, dl_train, DEVICE, epoch, criterion, optimizer, scheduler)\n",
    "    val_loss, val_acc, val_dice = cycle_seg('test', model, dl_val, DEVICE, epoch, criterion, optimizer)\n",
    "    x = val_dice.value\n",
    "    def find_Jaccard(x):\n",
    "        J= x/(2-x)\n",
    "        return J\n",
    "    \n",
    "    find_Jaccard(x)\n",
    " \n",
    "\n",
    "    print(f\"Epoch {epoch:03d}\\t\\t\\tTRAIN loss: {train_loss:.4f}\\tTRAIN Dice: {train_dice.value:.4f}\\tVAL loss: {val_loss:.4f}\\tVAL dice: {x:.4f}{'*' if x > best_dice else ''}\\tJaccard Index: {find_Jaccard(x):.4f}\")\n",
    "\n",
    "    state = {'epoch': epoch + 1,\n",
    "             'state_dict': model.state_dict(),\n",
    "             'optimizer': optimizer.state_dict(),\n",
    "             'scheduler': scheduler}\n",
    "    save_path = os.path.join(MODEL_DIR, f\"seg_unet_{epoch}_{val_dice.value:.07f}.pt\")\n",
    "    best_dice, last_save_path = save_state(state, save_path, val_dice.value, best_dice, last_save_path, lowest_best=False)\n",
    "\n",
    "# plot metrics\n",
    "pyplot.plot(history.history[train_dice.value])\n",
    "pyplot.plot(history.history[x])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a6ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
